{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.6.10 64-bit ('ma': conda)",
   "metadata": {
    "interpreter": {
     "hash": "739f6139ea16146f6825468ed5e82eb0c1c232f377b4e45bfd13eaa0a4a5ceb5"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Training and Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# system imports\n",
    "import os\n",
    "\n",
    "# additional imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "\n",
    "# device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "source": [
    "## Hyperparameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams = {    \n",
    "    \"epochs\": 20,\n",
    "    \"batch_size\": 8,\n",
    "    \"lr\": 1e-3,\n",
    "    \"features\": [\n",
    "        'chroma_stft', 'rmse', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate',\n",
    "        'mfcc1', 'mfcc2', 'mfcc3', 'mfcc4', 'mfcc5', 'mfcc6', 'mfcc7', 'mfcc8', 'mfcc9', 'mfcc10', \n",
    "        'mfcc11', 'mfcc12', 'mfcc13', 'mfcc14', 'mfcc15', 'mfcc16', 'mfcc17', 'mfcc18', 'mfcc19', 'mfcc20'\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "source": [
    "## Prepare Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "classes: ['covid' 'not_covid']\nX_train.shape: (113, 26)\ny_train.shape: (113,)\n"
     ]
    }
   ],
   "source": [
    "df_features = pd.read_csv(\"data/prepared_data.csv\")\n",
    "X = np.array(df_features[hparams['features']], dtype=np.float32)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(df_features['label'])\n",
    "print(\"classes:\", encoder.classes_)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# scale data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "\n",
    "# create pytorch dataloader\n",
    "torch.manual_seed(42)\n",
    "train_dataset = torch.utils.data.TensorDataset(torch.Tensor(X_train), torch.Tensor(y_train).long())\n",
    "test_dataset = torch.utils.data.TensorDataset(torch.Tensor(X_test), torch.Tensor(y_test).long())\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=hparams[\"batch_size\"], shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=hparams[\"batch_size\"], shuffle=False)"
   ]
  },
  {
   "source": [
    "## Setup Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Design model (input, output size, forward pass)\n",
    "class CoughNet(torch.nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(CoughNet, self).__init__()\n",
    "        self.l1 = torch.nn.Linear(input_size, 512)\n",
    "        self.l2 = torch.nn.Linear(512, 256)\n",
    "        self.l3 = torch.nn.Linear(256, 128)\n",
    "        self.l4 = torch.nn.Linear(128, 64)\n",
    "        self.l5 = torch.nn.Linear(64, 10)\n",
    "        self.l6 = torch.nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.l1(x))\n",
    "        x = torch.relu(self.l2(x))\n",
    "        x = torch.relu(self.l3(x))\n",
    "        x = torch.relu(self.l4(x))\n",
    "        x = torch.relu(self.l5(x))\n",
    "        x = self.l6(x)\n",
    "        return x\n",
    "\n",
    "model = CoughNet(len(hparams[\"features\"])).to(device)"
   ]
  },
  {
   "source": [
    "## Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Training Epoch 1]: 100%|██████████| 15/15 [00:00<00:00, 69.88it/s, loss=0.0761, train_accuracy=0.549]\n",
      "[Evaluating Epoch 1]: 100%|██████████| 8/8 [00:00<00:00, 189.05it/s, loss=0.0839, eval_accuracy=0.842]\n",
      "[Training Epoch 2]: 100%|██████████| 15/15 [00:00<00:00, 87.67it/s, loss=0.043, train_accuracy=0.912]\n",
      "[Evaluating Epoch 2]: 100%|██████████| 8/8 [00:00<00:00, 187.73it/s, loss=0.0882, eval_accuracy=0.842]\n",
      "[Training Epoch 3]: 100%|██████████| 15/15 [00:00<00:00, 92.64it/s, loss=0.0171, train_accuracy=0.912]\n",
      "[Evaluating Epoch 3]: 100%|██████████| 8/8 [00:00<00:00, 201.32it/s, loss=0.0606, eval_accuracy=0.842]\n",
      "[Training Epoch 4]: 100%|██████████| 15/15 [00:00<00:00, 81.11it/s, loss=0.0115, train_accuracy=0.912]\n",
      "[Evaluating Epoch 4]: 100%|██████████| 8/8 [00:00<00:00, 202.10it/s, loss=0.0965, eval_accuracy=0.842]\n",
      "[Training Epoch 5]: 100%|██████████| 15/15 [00:00<00:00, 79.83it/s, loss=0.00871, train_accuracy=0.947]\n",
      "[Evaluating Epoch 5]: 100%|██████████| 8/8 [00:00<00:00, 174.65it/s, loss=0.107, eval_accuracy=0.895]\n",
      "[Training Epoch 6]: 100%|██████████| 15/15 [00:00<00:00, 86.73it/s, loss=0.00768, train_accuracy=1]\n",
      "[Evaluating Epoch 6]: 100%|██████████| 8/8 [00:00<00:00, 181.46it/s, loss=0.127, eval_accuracy=0.912]\n",
      "[Training Epoch 7]: 100%|██████████| 15/15 [00:00<00:00, 72.52it/s, loss=0.00714, train_accuracy=1]\n",
      "[Evaluating Epoch 7]: 100%|██████████| 8/8 [00:00<00:00, 199.61it/s, loss=0.155, eval_accuracy=0.895]\n",
      "[Training Epoch 8]: 100%|██████████| 15/15 [00:00<00:00, 95.14it/s, loss=0.00699, train_accuracy=1]\n",
      "[Evaluating Epoch 8]: 100%|██████████| 8/8 [00:00<00:00, 174.95it/s, loss=0.168, eval_accuracy=0.912]\n",
      "[Training Epoch 9]: 100%|██████████| 15/15 [00:00<00:00, 88.62it/s, loss=0.00679, train_accuracy=1]\n",
      "[Evaluating Epoch 9]: 100%|██████████| 8/8 [00:00<00:00, 179.38it/s, loss=0.177, eval_accuracy=0.912]\n",
      "[Training Epoch 10]: 100%|██████████| 15/15 [00:00<00:00, 89.06it/s, loss=0.00629, train_accuracy=1]\n",
      "[Evaluating Epoch 10]: 100%|██████████| 8/8 [00:00<00:00, 198.70it/s, loss=0.179, eval_accuracy=0.93]\n",
      "[Training Epoch 11]: 100%|██████████| 15/15 [00:00<00:00, 76.88it/s, loss=0.00458, train_accuracy=1]\n",
      "[Evaluating Epoch 11]: 100%|██████████| 8/8 [00:00<00:00, 196.41it/s, loss=0.169, eval_accuracy=0.947]\n",
      "[Training Epoch 12]: 100%|██████████| 15/15 [00:00<00:00, 88.93it/s, loss=0.00169, train_accuracy=1]\n",
      "[Evaluating Epoch 12]: 100%|██████████| 8/8 [00:00<00:00, 189.24it/s, loss=0.202, eval_accuracy=0.947]\n",
      "[Training Epoch 13]: 100%|██████████| 15/15 [00:00<00:00, 85.44it/s, loss=0.00263, train_accuracy=0.991]\n",
      "[Evaluating Epoch 13]: 100%|██████████| 8/8 [00:00<00:00, 187.61it/s, loss=0.162, eval_accuracy=0.947]\n",
      "[Training Epoch 14]: 100%|██████████| 15/15 [00:00<00:00, 87.25it/s, loss=0.00163, train_accuracy=0.991]\n",
      "[Evaluating Epoch 14]: 100%|██████████| 8/8 [00:00<00:00, 175.31it/s, loss=0.23, eval_accuracy=0.947]\n",
      "[Training Epoch 15]: 100%|██████████| 15/15 [00:00<00:00, 83.78it/s, loss=0.000201, train_accuracy=1]\n",
      "[Evaluating Epoch 15]: 100%|██████████| 8/8 [00:00<00:00, 179.12it/s, loss=0.299, eval_accuracy=0.947]\n",
      "[Training Epoch 16]: 100%|██████████| 15/15 [00:00<00:00, 86.30it/s, loss=0.000226, train_accuracy=1]\n",
      "[Evaluating Epoch 16]: 100%|██████████| 8/8 [00:00<00:00, 193.27it/s, loss=0.301, eval_accuracy=0.947]\n",
      "[Training Epoch 17]: 100%|██████████| 15/15 [00:00<00:00, 85.44it/s, loss=0.000105, train_accuracy=1]\n",
      "[Evaluating Epoch 17]: 100%|██████████| 8/8 [00:00<00:00, 186.99it/s, loss=0.298, eval_accuracy=0.947]\n",
      "[Training Epoch 18]: 100%|██████████| 15/15 [00:00<00:00, 86.25it/s, loss=6.89e-5, train_accuracy=1]\n",
      "[Evaluating Epoch 18]: 100%|██████████| 8/8 [00:00<00:00, 184.20it/s, loss=0.296, eval_accuracy=0.947]\n",
      "[Training Epoch 19]: 100%|██████████| 15/15 [00:00<00:00, 90.24it/s, loss=4.83e-5, train_accuracy=1]\n",
      "[Evaluating Epoch 19]: 100%|██████████| 8/8 [00:00<00:00, 200.14it/s, loss=0.296, eval_accuracy=0.947]\n",
      "[Training Epoch 20]: 100%|██████████| 15/15 [00:00<00:00, 90.08it/s, loss=3.6e-5, train_accuracy=1]\n",
      "[Evaluating Epoch 20]: 100%|██████████| 8/8 [00:00<00:00, 201.13it/s, loss=0.296, eval_accuracy=0.947]\n"
     ]
    }
   ],
   "source": [
    "# Construct loss and optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=hparams[\"lr\"])\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(loader_train, model, optimizer, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_correct = 0.0\n",
    "    total = 0\n",
    "    pbar = tqdm(enumerate(loader_train), total=len(loader_train))\n",
    "    for batch_ndx, sample in pbar: \n",
    "        features, labels = sample[0].to(device), sample[1].to(device) \n",
    "\n",
    "        # forward pass and loss calculation\n",
    "        outputs = model(features)\n",
    "        loss = criterion(outputs, labels)  \n",
    "        \n",
    "        # backward pass    \n",
    "        loss.backward()\n",
    "        \n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # calculate metrics\n",
    "        running_loss += loss.item()\n",
    "        predictions = torch.argmax(outputs.data, 1)\n",
    "        running_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        # print informations\n",
    "        pbar.set_description(f\"[Training Epoch {epoch+1}]\") \n",
    "        total += labels.shape[0]\n",
    "        pbar.set_postfix({'loss': running_loss / total, 'train_accuracy': running_correct / total})\n",
    "\n",
    "def evaluate(loader_test, model, epoch):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_correct = 0.0\n",
    "        total = 0\n",
    "        pbar = tqdm(enumerate(loader_test), total=len(loader_test))\n",
    "        for batch_ndx, sample in pbar:\n",
    "            features, labels = sample[0].to(device), sample[1].to(device) \n",
    "\n",
    "            # forward pass and loss calculation\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, labels)  \n",
    "\n",
    "            # calculate metrics\n",
    "            running_loss += loss.item()\n",
    "            predictions = torch.argmax(outputs.data, 1)\n",
    "            running_correct += (predictions == labels).sum().item()\n",
    "\n",
    "            # print informations\n",
    "            pbar.set_description(f\"[Evaluating Epoch {epoch+1}]\")\n",
    "            total += labels.shape[0]\n",
    "            pbar.set_postfix({'loss': running_loss / total, 'eval_accuracy': running_correct / total})\n",
    "\n",
    "# training loop\n",
    "for epoch in range(hparams[\"epochs\"]):\n",
    "    train(train_loader, model, optimizer, epoch)\n",
    "    evaluate(test_loader, model, epoch)\n",
    "\n",
    "# save checkpoint after training\n",
    "checkpoint = {\n",
    "    'hparams': hparams,\n",
    "    'model_state': model.state_dict(),\n",
    "    'scaler': scaler,\n",
    "    'encoder': encoder\n",
    "}\n",
    "torch.save(checkpoint, \"checkpoints/checkpoint.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}